{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set-up for Intensity-binning analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# uncomment the following line when you want to interact with the matplotlib plots\n",
        "#%matplotlib widget\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colormaps\n",
        "cmap = colormaps.get_cmap('plasma')\n",
        "from scipy.special import erf\n",
        "from fermi_libraries.run_module import Run, RunSets\n",
        "from fermi_libraries.common_functions import (\n",
        "    rebinning, tof_mq_calibration, simplify_data, \n",
        "    tof_to_mq_conversion, mq_to_tof_conversion,\n",
        "    tof_to_ke_conversion, ke_to_tof_conversion, \n",
        "    name_from_runs,\n",
        "    avg_from_moments, stdev_from_moments,\n",
        "    set_default_labels,\n",
        "    set_recursion_limit,\n",
        "    closest)\n",
        "from fermi_libraries.dictionary_search import search_symbols"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function definitions (that you might change)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "@set_recursion_limit(1)\n",
        "def keyword_functions(keyword, aliasFunc, DictionaryObject):\n",
        "\n",
        "    if False:\n",
        "        pass\n",
        "\n",
        "    elif keyword=='bunch_parity':\n",
        "        bunches = DictionaryObject['bunches'][()]\n",
        "        parity = bunches%2==0\n",
        "        return parity\n",
        "\n",
        "    elif keyword=='fel_wavelengths':\n",
        "        padres_span = DictionaryObject['/photon_diagnostics/Spectrometer/WavelengthSpan'][()]\n",
        "        padres_wavelength = DictionaryObject['/photon_diagnostics/Spectrometer/Wavelength'][()] + 0.0575\n",
        "        padres_pixel2micron = DictionaryObject['/photon_diagnostics/Spectrometer/Pixel2micron'][()]\n",
        "        padres_lambda = padres_wavelength + np.arange(-500, 500) * padres_pixel2micron * padres_span / 1000\n",
        "        return padres_lambda\n",
        "    \n",
        "    elif keyword=='fel_wavelengths_avg':\n",
        "        fel_lambda = keyword_functions('fel_wavelengths', aliasFunc, DictionaryObject)\n",
        "        fel_spectrum = DictionaryObject['photon_diagnostics/Spectrometer/hor_spectrum'][()]\n",
        "        average = avg_from_moments(fel_lambda, fel_spectrum, L=0.5)\n",
        "        return average\n",
        "\n",
        "    elif keyword=='fel_wavelengths_stdev':\n",
        "        fel_lambda = keyword_functions('fel_wavelengths', aliasFunc, DictionaryObject)\n",
        "        fel_spectrum = DictionaryObject['photon_diagnostics/Spectrometer/hor_spectrum'][()]\n",
        "        stdev = stdev_from_moments(fel_lambda, fel_spectrum, L=0.5)\n",
        "        return stdev\n",
        "\n",
        "    elif keyword=='seed_wavelengths_avg':\n",
        "        seed_spectrum = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/WaveMeta'][()]\n",
        "        seed_lambda = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/LambdaMeta'][()]\n",
        "        average = avg_from_moments(seed_lambda, seed_spectrum, L=0.5)\n",
        "        return average\n",
        "\n",
        "    elif keyword=='seed_wavelengths_stdev':\n",
        "        seed_spectrum = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/WaveMeta'][()]\n",
        "        seed_lambda = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/LambdaMeta'][()]\n",
        "        stdev = stdev_from_moments(seed_lambda, seed_spectrum, L=0.5)\n",
        "        return stdev\n",
        "\n",
        "    elif keyword=='total_retardation':\n",
        "        voltage_1 = DictionaryObject['endstation/MagneticBottle/voltage_ch1'][()]\n",
        "        voltage_2 = DictionaryObject['endstation/MagneticBottle/voltage_ch2'][()]\n",
        "        voltage_3 = DictionaryObject['endstation/MagneticBottle/voltage_ch3'][()]\n",
        "        voltage_1_on = DictionaryObject['endstation/MagneticBottle/ch1_is_enabled'][()]\n",
        "        voltage_2_on = DictionaryObject['endstation/MagneticBottle/ch2_is_enabled'][()]\n",
        "        voltage_3_on = DictionaryObject['endstation/MagneticBottle/ch3_is_enabled'][()]\n",
        "        retardation = voltage_1*voltage_1_on + voltage_2*voltage_2_on - voltage_3*voltage_3_on\n",
        "        return retardation\n",
        "\n",
        "    else:\n",
        "        return DictionaryObject[aliasFunc(keyword)]\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alias definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Figure bookkeeping to save memory\n",
        "figs = {}\n",
        "def newfig(id, *args, **kwargs):\n",
        "    id = 0\n",
        "    if id in figs:\n",
        "        plt.close(figs[id].number)\n",
        "    fig, ax = plt.subplots(*args, **kwargs)\n",
        "    figs.update({id: fig})\n",
        "    return fig, ax\n",
        "\n",
        "# Alternative names for the HDF5 groupnames\n",
        "alias_dict = {\n",
        "    'i0m' : 'photon_diagnostics/FEL01/I0_monitor/iom_sh_a',\n",
        "    'i0m_current' : 'photon_diagnostics/FEL01/I0_monitor/iom_sh_a_pc',\n",
        "    'vmi' : 'vmi/andor',\n",
        "    'ion_tof' : 'digitizer/channel1',\n",
        "    'delay' : 'user_laser/delay_line/position',\n",
        "    'slu' : 'user_laser/energy_meter/Energy2',\n",
        "    'fel_spectrometer' : 'photon_diagnostics/Spectrometer/hor_spectrum',\n",
        "    'fel_wavelength' : 'photon_source/FEL01/wavelength',\n",
        "    'seed_spectrometer' : 'photon_source/SeedLaserSpectrum_FEL01/WaveMeta',\n",
        "    'seed_wavelength' : 'photon_source/SeedLaser/Wavelength',\n",
        "    'seed_wavelengths' : 'photon_source/SeedLaserSpectrum_FEL01/LambdaMeta',\n",
        "    'harmonic_number' : 'photon_source/FEL01/harmonic_number',\n",
        "    'bunch_number' : 'bunches',\n",
        "    'pressure' : 'photon_diagnostics/FEL01/Gas_Attenuator/Pressure',\n",
        "    'poletto' : 'cosp/HorSpectrum',\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ------------------------------------------------------------------------------------------------\n",
        "# ! Data selection ! -----------------------------------------------------------------------------\n",
        "\n",
        "This block contains the variables you might change every different Run. \n",
        "Changing \"ion_tof_range\" or \"eon_tof_range\" __does not__ make the program run faster; we are limited\n",
        "by the compression in FERMI's HDF5 files. If working memory is a problem, then decrease these\n",
        "ranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# BEAMTIME_DIR =  '/net/online4ldm/store/20209112b/results/TestData/'\n",
        "BEAMTIME_DIR =  'TestBeamtime/'\n",
        "DATA_DIR = BEAMTIME_DIR+'Beamtime/'  # change from fictitious to the real raw data directory!\n",
        "SAVE_DIR = BEAMTIME_DIR+'results/evaluation/'#'/net/online4ldm/store/20209134/results/results' # ditto\n",
        "\n",
        "SAVE_FILES = False\n",
        "\n",
        "BACKGROUND = True  # Only set to False if you want to sum up everything\n",
        "NAMEADD = 'test' # your name here\n",
        "run_numbers = np.arange(1,3)\n",
        "\n",
        "\n",
        "# variables for data extraction ans rebinning\n",
        "ION_TOF_REBIN = 10\n",
        "ion_tof_range = (4000, 30000, 1) # select ion tof range for plotting\n",
        "new_ion_mq = np.linspace(0.1,200,num=1200)\n",
        "\n",
        "EON_TOF_REBIN = 1\n",
        "eon_tof_range = (4000, 10000, 1)\n",
        "new_eKE = np.linspace(0.5, 50, num=400)\n",
        "\n",
        "ion_tof_slices = [ion_tof_range]\n",
        "eon_tof_slices = [eon_tof_range]\n",
        "\n",
        "ion_tof = np.arange(*ion_tof_slices[0])\n",
        "rebin_ion_tof = ion_tof[::ION_TOF_REBIN]\n",
        "eon_tof = np.arange(*eon_tof_slices[0])\n",
        "rebin_eon_tof = eon_tof[::EON_TOF_REBIN]\n",
        "\n",
        "MAKE_CACHE = True\n",
        "LOAD_FROM_CACHE = False\n",
        "\n",
        "calibration_run_number = 1\n",
        "\n",
        "print(run_numbers)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create RunCollection (main data structure), and print location of our save directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# This block loads all the relevent HDF5 filepaths into their respective Run.\n",
        "RunCollection = {}  # We will put all the 'Runs' in thes dictionary\n",
        "for run_id in (list(run_numbers) + [calibration_run_number,]):\n",
        "    folderpath = os.path.join(DATA_DIR, f'Run_{run_id:03d}/rawdata')\n",
        "    filepaths = [folderpath+'/'+filename for filename in os.listdir(folderpath)[::]]\n",
        "    RunCollection[run_id] = Run(filepaths,\n",
        "                                alias_dict=alias_dict, search_symbols=search_symbols,\n",
        "                                keyword_functions=keyword_functions,\n",
        "                                )  # create a Run object with its respective filepaths\n",
        "\n",
        "# This creates a set out of the run_numbers selected above\n",
        "BasicRunSet = RunSets([])\n",
        "for run in run_numbers:\n",
        "    BasicRunSet.add([RunCollection[run]])\n",
        "print(f'Data set contains {len(BasicRunSet.run_instances)} run(s).')\n",
        "\n",
        "run_name = f'Runs {run_numbers[0]}-{run_numbers[-1]}'\n",
        "run_string = name_from_runs(run_numbers)\n",
        "prefix = os.path.join(SAVE_DIR, run_string)\n",
        "outdir = (prefix + '_' + NAMEADD).rstrip('_')\n",
        "print(f'Save directory: ...{outdir[30:]}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create directory if non-existent (and if we are actually saving files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if SAVE_FILES:\n",
        "    if not os.path.exists(outdir):\n",
        "        os.mkdir(outdir)\n",
        "\n",
        "# %% testing here, delete when done!\n",
        "\n",
        "runset_ion_tof_data = BasicRunSet.average_run_data('fel_wavelengths_avg', back_sep=BACKGROUND,\n",
        "                                    make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ------------------------------------------------------------------------------------------------\n",
        "# Show the average background-subtracted electron TOF for each Run ---------------------\n",
        "\n",
        "The output for Runset.averageRunData and Runset.average_run_data_weights has the\n",
        "axes shape (rule, condition, run, data):\n",
        "\"rule\" are the filtering rules\n",
        "\"condition\" is in the order (FEL:ON SLU:ON, FEL:OFF SLU:ON, FEL:ON SLU:OFF, FEL:OFF SLU:OFF)\n",
        "\"run\" are the individual Runs\n",
        "\"data\" is the average rundata/weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "runset_ion_tof_data = BasicRunSet.average_run_data('ion_tof', back_sep=BACKGROUND,\n",
        "                                    slice_range=ion_tof_slices,\n",
        "                                    make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
        "fore_ion_rundata, back_ion_rundata = simplify_data(runset_ion_tof_data, single_rule=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "overall_integral_eKE = []\n",
        "# fel_energys = nm_to_ev(fel_wavelengths)\n",
        "\n",
        "subt_ion_tof_rundata = -(fore_ion_rundata - back_ion_rundata)\n",
        "rebin_ion_tof_rundata = rebinning(rebin_ion_tof, ion_tof, subt_ion_tof_rundata, axis=1)\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
        "for (runnumber, ion_spectrum_tof) in zip(\n",
        "    run_numbers, rebin_ion_tof_rundata):\n",
        "    ax.plot(rebin_ion_tof, ion_spectrum_tof, label=f\"Run_{runnumber:03d}\")\n",
        "\n",
        "ax.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
        "ax.set_xlabel('ion TOF')\n",
        "ax.set_ylabel('ion TOF signal; rebinned (arb.u.)')\n",
        "ax.set_title(f'{run_name}: run averages')\n",
        "\n",
        "# if SAVE_FILES:\n",
        "#     fig.savefig(outdir+'/Average_of_complete_run.png')\n",
        "#     fig1.savefig(outdir+'/Average_of_complete_run_eV.png')\n",
        "ax.set_ylim(-1,1)\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "ion_tof_mq_peaks = np.array([\n",
        "    # [5000, 999],\n",
        "    [6000, 0],\n",
        "    [10500, 14],\n",
        "    [12000, 28],\n",
        "    [13100, 36],\n",
        "\n",
        "])\n",
        "tof_points, mq_points = ion_tof_mq_peaks.T\n",
        "\n",
        "ion_cal_rundata = RunCollection[calibration_run_number].average_run_data('ion_tof', back_sep=BACKGROUND,\n",
        "                                    slice_range=ion_tof_slices,\n",
        "                                    make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
        "fore_ion_rundata, back_ion_rundata = simplify_data(ion_cal_rundata)\n",
        "cal_sub_spectrum = back_ion_rundata[:,0] - fore_ion_rundata[:,0]\n",
        "\n",
        "\n",
        "ion_calibration_dict = tof_mq_calibration(peaks=ion_tof_mq_peaks)\n",
        "(tof_mq_coor_func, tof_mq_jaco_func,\n",
        " mq_tof_coor_func, mq_tof_jaco_func,\n",
        " ion_constants_dict) = list(ion_calibration_dict.values())\n",
        "print(f'calibration constants:  {ion_constants_dict}')\n",
        "ion_constants = ion_constants_dict['timezero'], ion_constants_dict['C']\n",
        "\n",
        "model_tof = np.linspace(np.min(tof_points), np.max(tof_points), num=1000)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,4))\n",
        "ax1.plot(tof_points, cal_sub_spectrum[closest(tof_points, ion_tof)], marker='v', linestyle='')\n",
        "ax1.plot(ion_tof, cal_sub_spectrum)\n",
        "# ax1.set_xlim(5000,7000)\n",
        "set_default_labels(ax1, title='calibration points', xlabel='tof (ns)', ylabel='tof (ns)')\n",
        "ax2.plot(tof_points, mq_points, marker='o', linestyle='')\n",
        "ax2.plot(model_tof, tof_mq_coor_func(model_tof), color='black')\n",
        "set_default_labels(ax2, title='calibration fit', xlabel='tof (ns)', ylabel='m/q')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Using ion constants: (t0, C) = {ion_constants}\")\n",
        "tof_to_mq = lambda tof, spec: tof_to_mq_conversion(tof, spec, *ion_constants)\n",
        "mq_to_tof = lambda mq, spec: mq_to_tof_conversion(mq, spec, *ion_constants)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,4))\n",
        "for (runnumber, ion_spectrum_tof) in zip(\n",
        "    run_numbers, rebin_ion_tof_rundata):\n",
        "    ax1.plot(rebin_ion_tof, ion_spectrum_tof, label=f\"Run_{runnumber:03d}\")\n",
        "\n",
        "ax1.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
        "ax1.set_xlabel('ion TOF')\n",
        "ax1.set_ylabel('ion TOF signal; rebinned (arb.u.)')\n",
        "ax1.set_title(f'{run_name}: run averages')\n",
        "ax1.set_yscale('log')\n",
        "ylim = ax1.set_ylim()\n",
        "ax1.set_ylim(ylim[1]*1e-4, ylim[1])\n",
        "\n",
        "for (runnumber, ion_spectrum_tof) in zip(\n",
        "    run_numbers, rebin_ion_tof_rundata):\n",
        "    mq_coor, mq_spectrum = tof_to_mq(rebin_ion_tof, -ion_spectrum_tof)\n",
        "    rebin_mq = np.linspace(0.1, 70, num=1000)\n",
        "    rebin_mq_spectrum = rebinning(rebin_mq, mq_coor, mq_spectrum)\n",
        "    ax2.plot(rebin_mq, rebin_mq_spectrum, label=f\"Run_{runnumber:03d}\")\n",
        "\n",
        "ax2.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
        "ax2.set_xlabel('mq')\n",
        "ax2.set_ylabel('ion TOF signal; rebinned (arb.u.)')\n",
        "ax2.set_yscale('log')\n",
        "ylim = ax2.set_ylim()\n",
        "ax2.set_ylim(ylim[1]*1e-4, ylim[1])\n",
        "ax2.set_title(f'{run_name}: run averages')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ------------------------------------------------------------------------------------------------\n",
        "# I0M filtering -----------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "raw_i0m_rundata = BasicRunSet.give_rundata('i0m', make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
        "try:\n",
        "    i0m_runset_data, _ = simplify_data(raw_i0m_rundata, single_rule=True)  # can use simplify_data, because no rules\n",
        "except:\n",
        "    fore_rundata_i0m, back_rundata_iom, *_ = raw_i0m_rundata\n",
        "    i0m_runset_data = fore_rundata_i0m\n",
        "    for i in range(len(i0m_runset_data)):  # collapse the rule dimension\n",
        "        i0m_runset_data[i] = i0m_runset_data[i][0]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check the range of possible I0M intensities here; change I0M binning in the next block if needed!\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(8,3))\n",
        "for runnumber, i0m_run_data in zip(run_numbers, i0m_runset_data):\n",
        "    i0m_data = i0m_run_data[:,0]  # just collapsing an extraneous dimension\n",
        "    ax1.plot(i0m_data, marker='o', markersize=1, linestyle='', label=f'Run_{runnumber:03d}')\n",
        "    ax2.hist(i0m_data, bins=np.linspace(min(i0m_data),max(i0m_data),num=100),\n",
        "             label=f'Run_{runnumber:03d}')\n",
        "ax1.set_ylabel('I0M intensity (uJ)')\n",
        "ax1.set_xlabel('shot number')\n",
        "ax1.set_title(f'{run_name}: I0M over time')\n",
        "#ax1.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
        "\n",
        "ax2.set_ylabel('binned counts')\n",
        "ax2.set_xlabel('I0M (uJ)')\n",
        "ax2.set_title(f'{run_name}: Histogram of I0M')\n",
        "#ax2.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
        "plt.tight_layout()\n",
        "\n",
        "if SAVE_FILES:\n",
        "    plt.savefig(outdir+'/I0M_time_and_bins.png')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%time # uncomment to show time\n",
        "runset_vmi = BasicRunSet.average_run_data('vmi',back_sep=BACKGROUND,\n",
        "                                    make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
        "fore_vmi, back_vmi = simplify_data(runset_vmi, single_rule=True, single_run=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sub_vmi = fore_vmi - back_vmi\n",
        "print(np.shape(sub_vmi))\n",
        "plt.imshow(np.average(sub_vmi, axis=0))\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}