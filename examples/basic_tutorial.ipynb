{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import statements\n",
        "\n",
        "- numpy, matplotlib are the usual libraries.\n",
        "\n",
        "- fermi_libraries.run_module contains the data structure scripts used for compiling the raw data into easy-to-handle data.\n",
        "\n",
        "- fermi_libraries.common_functions has generally useful functions with no specific goal.\n",
        "\n",
        "- fermi_libraries.dictionary_search allows the filter capability of the Run.give_average_data() functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# uncomment the following line when you want to interact with the matplotlib plots\n",
        "#%matplotlib widget\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colormaps\n",
        "from fermi_libraries.run_module import Run, RunSets\n",
        "from fermi_libraries.common_functions import (\n",
        "    rebinning, simplify_data, weighted_linear_regression,\n",
        "    avg_from_moments, stdev_from_moments,\n",
        "    name_from_runs,\n",
        "    set_default_labels,\n",
        "    set_recursion_limit,\n",
        "    closest,\n",
        "    )\n",
        "from fermi_libraries.dictionary_search import search_symbols\n",
        "import pathlib"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There's a difference between looking for the current script location when running .py vs .ipynb files. This is the best way I could come up with to make things work for both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    CURRENT_SCRIPT_DIR = str(pathlib.Path(__file__).parent.resolve())+'/'\n",
        "except NameError:  # this will happen in .ipynb files\n",
        "    CURRENT_SCRIPT_DIR = os.path.abspath('')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function definitions (that you might change)\n",
        "\n",
        "This extends our filtering capabilities from simple things (e.g. I0M>5) anything\n",
        "you want. For example, if we want to filter by the averages of the TOF spectra,\n",
        "we would define some other keyword function as \"average_TOF\", and write a rule\n",
        "such as \"average_TOF>4\". Here is an extreme example below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@set_recursion_limit(1)\n",
        "def keyword_functions(keyword, aliasFunc, DictionaryObject):\n",
        "    if False:\n",
        "        pass\n",
        "\n",
        "    elif keyword=='bunch_parity':\n",
        "        bunches = DictionaryObject['bunches'][()]\n",
        "        parity = bunches%2==0\n",
        "        return parity\n",
        "\n",
        "    elif keyword=='fel_wavelengths':\n",
        "        padres_span = DictionaryObject['/photon_diagnostics/Spectrometer/WavelengthSpan'][()]\n",
        "        padres_wavelength = DictionaryObject['/photon_diagnostics/Spectrometer/Wavelength'][()] + 0.0575\n",
        "        padres_pixel2micron = DictionaryObject['/photon_diagnostics/Spectrometer/Pixel2micron'][()]\n",
        "        padres_lambda = padres_wavelength + np.arange(-500, 500) * padres_pixel2micron * padres_span / 1000\n",
        "        return padres_lambda\n",
        "    \n",
        "    elif keyword=='fel_wavelengths_avg':\n",
        "        fel_lambda = keyword_functions('fel_wavelengths', aliasFunc, DictionaryObject)\n",
        "        fel_spectrum = DictionaryObject['photon_diagnostics/Spectrometer/hor_spectrum'][()]\n",
        "        average = avg_from_moments(fel_lambda, fel_spectrum, L=0.5)\n",
        "        return average\n",
        "\n",
        "    elif keyword=='fel_wavelengths_stdev':\n",
        "        fel_lambda = keyword_functions('fel_wavelengths', aliasFunc, DictionaryObject)\n",
        "        fel_spectrum = DictionaryObject['photon_diagnostics/Spectrometer/hor_spectrum'][()]\n",
        "        stdev = stdev_from_moments(fel_lambda, fel_spectrum, L=0.5)\n",
        "        return stdev\n",
        "\n",
        "    elif keyword=='seed_wavelengths_avg':\n",
        "        seed_spectrum = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/WaveMeta'][()]\n",
        "        seed_lambda = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/LambdaMeta'][()]\n",
        "        average = avg_from_moments(seed_lambda, seed_spectrum, L=0.5)\n",
        "        return average\n",
        "\n",
        "    elif keyword=='seed_wavelengths_stdev':\n",
        "        seed_spectrum = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/WaveMeta'][()]\n",
        "        seed_lambda = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/LambdaMeta'][()]\n",
        "        stdev = stdev_from_moments(seed_lambda, seed_spectrum, L=0.5)\n",
        "        return stdev\n",
        "\n",
        "    elif keyword=='total_retardation':\n",
        "        voltage_1 = DictionaryObject['endstation/MagneticBottle/voltage_ch1'][()]\n",
        "        voltage_2 = DictionaryObject['endstation/MagneticBottle/voltage_ch2'][()]\n",
        "        voltage_3 = DictionaryObject['endstation/MagneticBottle/voltage_ch3'][()]\n",
        "        voltage_1_on = DictionaryObject['endstation/MagneticBottle/ch1_is_enabled'][()]\n",
        "        voltage_2_on = DictionaryObject['endstation/MagneticBottle/ch2_is_enabled'][()]\n",
        "        voltage_3_on = DictionaryObject['endstation/MagneticBottle/ch3_is_enabled'][()]\n",
        "        retardation = voltage_1*voltage_1_on + voltage_2*voltage_2_on - voltage_3*voltage_3_on\n",
        "        return retardation\n",
        "\n",
        "    else:\n",
        "        return DictionaryObject[aliasFunc(keyword)]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alias definitions\n",
        "\n",
        "This lets us re-name the long HDF5 groupnames into more intuitive names e.g.\n",
        "\"digitizer/channel1\" -> \"ion_tof\".\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Alternative names for the HDF5 groupnames\n",
        "alias_dict = {\n",
        "    'vmi' : 'vmi/andor',\n",
        "    'ion_tof' : 'digitizer/channel1',\n",
        "    'delay' : 'user_laser/delay_line/position',\n",
        "    'slu' : 'user_laser/energy_meter/Energy2',\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **Data selection**\n",
        "\n",
        "This is the \"options\" part of the scripts, which we expect to change depending\n",
        "on what we want. e.g. To look at different \"Runs\", we would change the\n",
        "run_numbers variable.\n",
        "\n",
        "Cacheing is provided as an option, to avoid recompiling raw data.\n",
        "\n",
        "Maybe the \"CURRENT_SCRIPT_DIR\" is wrong, so you will have to adjust this\n",
        "yourself; this is only an issue when we're all testing the scripts on our own\n",
        "computers. Once we're all at the endstation, this will be fixed without any more\n",
        "ambiguity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# BEAMTIME_DIR =  '/net/online4ldm/store/20234049/results/Beamtime/'  # expected directory at FERMI\n",
        "BEAMTIME_DIR =  f'{CURRENT_SCRIPT_DIR}/TestBeamtime/'\n",
        "DATA_DIR = f'{BEAMTIME_DIR}/Beamtime/'  # change from fictitious to the real raw data directory!\n",
        "SAVE_DIR = f'{BEAMTIME_DIR}/results/evaluation/'#'/net/online4ldm/store/20234049/results/results' # ditto\n",
        "\n",
        "SAVE_FILES = False\n",
        "\n",
        "BACKGROUND = True  # Only set to False if you want to sum up everything\n",
        "NAMEADD = 'test' # your name here\n",
        "run_numbers = [1,]\n",
        "\n",
        "MAKE_CACHE = True\n",
        "LOAD_FROM_CACHE = False\n",
        "\n",
        "CALIBRATION_RUN_NUMBER = 1\n",
        "\n",
        "print(run_numbers)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create RunCollection (main data structure), and print location of our save\n",
        "directory. I don't expect this to ever change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# This block loads all the relevent HDF5 filepaths into their respective Run.\n",
        "RunCollection = {}  # We will put all the 'Runs' in thes dictionary\n",
        "for run_id in (list(run_numbers) + [CALIBRATION_RUN_NUMBER,]):\n",
        "    folderpath = os.path.join(DATA_DIR, f'Run_{run_id:03d}/rawdata')\n",
        "    filepaths = [folderpath+'/'+filename for filename in os.listdir(folderpath)[::]]\n",
        "    RunCollection[run_id] = Run(filepaths,\n",
        "                                alias_dict=alias_dict, search_symbols=search_symbols,\n",
        "                                keyword_functions=keyword_functions,\n",
        "                                )  # create a Run object with its respective filepaths\n",
        "\n",
        "# This is a single Run object\n",
        "CalibrationRun = RunCollection[CALIBRATION_RUN_NUMBER]\n",
        "\n",
        "# This creates a RunSet object\n",
        "BasicRunSet = RunSets([])\n",
        "for run in run_numbers:\n",
        "    BasicRunSet.add([RunCollection[run]])\n",
        "print(f'Data set contains {len(BasicRunSet.run_instances)} run(s).')\n",
        "\n",
        "run_name = f'Runs {run_numbers[0]}-{run_numbers[-1]}'\n",
        "run_string = name_from_runs(run_numbers)\n",
        "prefix = os.path.join(SAVE_DIR, run_string)\n",
        "outdir = (prefix + '_' + NAMEADD).rstrip('_')\n",
        "print(f'Save directory: ...{outdir[30:]}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create directory if non-existent (and if we are actually saving files)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if SAVE_FILES:\n",
        "    if not os.path.exists(outdir):\n",
        "        os.mkdir(outdir)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Data compilation\n",
        "\n",
        "Finally load some data! This is our bread-and-butter function to\n",
        "load/filter/separate raw data, and compile into a more useful form.\n",
        "\n",
        "**Everything stems from this function**. Play around with it!\n",
        "\n",
        "The output for Runset.averageRunData and Runset.average_run_data_weights has the\n",
        "axes shape (rule, condition, run, data):\n",
        "\n",
        "- \"rule\" are the filtering rules\n",
        "- \"condition\" is in the order (FEL:ON SLU:ON, FEL:OFF SLU:ON, FEL:ON SLU:OFF, FEL:OFF SLU:OFF)\n",
        "- \"run\" are the individual Runs\n",
        "- \"data\" is the average rundata/weights\n",
        "\n",
        "If you ever get confused on the output_data you're getting, you can deduce which\n",
        "axis stands for what by looking at the shape of the output_data:\n",
        "\n",
        "> print(np.shape(output_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is an example of using a \"Run\" object. This represents a single measurement and its replicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##%%time\n",
        "single_run_vmi = CalibrationRun.average_run_data('vmi',back_sep=BACKGROUND,\n",
        "                                    make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
        "print(f'shape of output data is: {np.shape(single_run_vmi)}')\n",
        "print('data has axes (condition, rules, ...data...)')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is an example of using a \"RunSet\" object. This represents multiple measurements, and is what we will typically use all the time out of convenience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##%%time\n",
        "runset_vmi = BasicRunSet.average_run_data('vmi',back_sep=BACKGROUND,\n",
        "                                    make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
        "print(f'shape of output data is: {np.shape(runset_vmi)}')\n",
        "print('data has axes (condition, run, rules, ...data...)')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "More often than not, we're looking at only a single Run, or aren't doing any\n",
        "filtering rules. So we can get rid of the axes by using this simplify() function\n",
        "as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fore_vmi, back_vmi = simplify_data(runset_vmi, single_rule=True, single_run=True)\n",
        "print(f'shape of fore data is: {np.shape(fore_vmi)}')\n",
        "print('data has axes (...data...)')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you understand the what the average_run_data() and simplify_data()\n",
        "functions do and give, everything else is just plotting and comparisons, and you\n",
        "can do as you wish!\n",
        "\n",
        "To see examples of plotting and comparisons, you can refer to the other scripts in the ./examples/ folder.\n",
        "\n",
        "Here's an easy plot example below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(fore_vmi - back_vmi)\n",
        "plt.title('Example of a VMI image!')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}