{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up for delay analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line when you want to interact with the matplotlib plots\n",
    "#%matplotlib widget\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "cmap = colormaps.get_cmap('plasma')\n",
    "from scipy.special import erf\n",
    "from fermi_libraries.run_module import Run, RunSets\n",
    "from fermi_libraries.common_functions import (\n",
    "    rebinning, simplify_data, name_from_runs, avg_from_moments, stdev_from_moments,\n",
    "    set_recursion_limit, resolve_path, find_subdir)\n",
    "from fermi_libraries.calibration_tools import (\n",
    "    tof_to_mq_conversion, mq_to_tof_conversion, )\n",
    "from fermi_libraries.dictionary_search import search_symbols\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    CURRENT_SCRIPT_DIR = str(pathlib.Path(__file__).parent.resolve())+'/'\n",
    "except NameError:  # this will happen in .ipynb files\n",
    "    CURRENT_SCRIPT_DIR = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions (that you might change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@set_recursion_limit(1)\n",
    "def keyword_functions(keyword, aliasFunc, DictionaryObject):\n",
    "\n",
    "    if False:\n",
    "        pass\n",
    "\n",
    "    elif keyword=='bunch_parity':\n",
    "        bunches = DictionaryObject['bunches'][()]\n",
    "        parity = bunches%2==0\n",
    "        return parity\n",
    "\n",
    "    elif keyword=='fel_wavelengths':\n",
    "        padres_span = DictionaryObject['/photon_diagnostics/Spectrometer/WavelengthSpan'][()]\n",
    "        padres_wavelength = DictionaryObject['/photon_diagnostics/Spectrometer/Wavelength'][()] + 0.0575\n",
    "        padres_pixel2micron = DictionaryObject['/photon_diagnostics/Spectrometer/Pixel2micron'][()]\n",
    "        padres_lambda = padres_wavelength + np.arange(-500, 500) * padres_pixel2micron * padres_span / 1000\n",
    "        return padres_lambda\n",
    "    \n",
    "    elif keyword=='fel_wavelengths_avg':\n",
    "        fel_lambda = keyword_functions('fel_wavelengths', aliasFunc, DictionaryObject)\n",
    "        fel_spectrum = DictionaryObject['photon_diagnostics/Spectrometer/hor_spectrum'][()]\n",
    "        average = avg_from_moments(fel_lambda, fel_spectrum, L=0.5)\n",
    "        return average\n",
    "\n",
    "    elif keyword=='fel_wavelengths_stdev':\n",
    "        fel_lambda = keyword_functions('fel_wavelengths', aliasFunc, DictionaryObject)\n",
    "        fel_spectrum = DictionaryObject['photon_diagnostics/Spectrometer/hor_spectrum'][()]\n",
    "        stdev = stdev_from_moments(fel_lambda, fel_spectrum, L=0.5)\n",
    "        return stdev\n",
    "\n",
    "    elif keyword=='seed_wavelengths_avg':\n",
    "        seed_spectrum = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/WaveMeta'][()]\n",
    "        seed_lambda = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/LambdaMeta'][()]\n",
    "        average = avg_from_moments(seed_lambda, seed_spectrum, L=0.5)\n",
    "        return average\n",
    "\n",
    "    elif keyword=='seed_wavelengths_stdev':\n",
    "        seed_spectrum = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/WaveMeta'][()]\n",
    "        seed_lambda = DictionaryObject['photon_source/SeedLaserSpectrum_FEL01/LambdaMeta'][()]\n",
    "        stdev = stdev_from_moments(seed_lambda, seed_spectrum, L=0.5)\n",
    "        return stdev\n",
    "\n",
    "    elif keyword=='total_retardation':\n",
    "        voltage_1 = DictionaryObject['endstation/MagneticBottle/voltage_ch1'][()]\n",
    "        voltage_2 = DictionaryObject['endstation/MagneticBottle/voltage_ch2'][()]\n",
    "        voltage_3 = DictionaryObject['endstation/MagneticBottle/voltage_ch3'][()]\n",
    "        voltage_1_on = DictionaryObject['endstation/MagneticBottle/ch1_is_enabled'][()]\n",
    "        voltage_2_on = DictionaryObject['endstation/MagneticBottle/ch2_is_enabled'][()]\n",
    "        voltage_3_on = DictionaryObject['endstation/MagneticBottle/ch3_is_enabled'][()]\n",
    "        retardation = voltage_1*voltage_1_on + voltage_2*voltage_2_on - voltage_3*voltage_3_on\n",
    "        return retardation\n",
    "\n",
    "    else:\n",
    "        return DictionaryObject[aliasFunc(keyword)]\n",
    "# %%\n",
    "\"\"\"\n",
    "### Alias definitions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure bookkeeping to save memory\n",
    "figs = {}\n",
    "def newfig(id, *args, **kwargs):\n",
    "    id = 0\n",
    "    if id in figs:\n",
    "        plt.close(figs[id].number)\n",
    "    fig, ax = plt.subplots(*args, **kwargs)\n",
    "    figs.update({id: fig})\n",
    "    return fig, ax\n",
    "\n",
    "# Alternative names for the HDF5 groupnames\n",
    "alias_dict = {\n",
    "    'i0m' : 'photon_diagnostics/FEL01/I0_monitor/iom_sh_a',\n",
    "    'i0m_current' : 'photon_diagnostics/FEL01/I0_monitor/iom_sh_a_pc',\n",
    "    'vmi' : 'vmi/andor',\n",
    "    'ion_tof' : 'digitizer/channel1',\n",
    "    'delay' : 'user_laser/delay_line/position',\n",
    "    'slu' : 'user_laser/energy_meter/Energy2',\n",
    "    'fel_spectrometer' : 'photon_diagnostics/Spectrometer/hor_spectrum',\n",
    "    'fel_wavelength' : 'photon_source/FEL01/wavelength',\n",
    "    'seed_spectrometer' : 'photon_source/SeedLaserSpectrum_FEL01/WaveMeta',\n",
    "    'seed_wavelength' : 'photon_source/SeedLaser/Wavelength',\n",
    "    'seed_wavelengths' : 'photon_source/SeedLaserSpectrum_FEL01/LambdaMeta',\n",
    "    'harmonic_number' : 'photon_source/FEL01/harmonic_number',\n",
    "    'bunch_number' : 'bunches',\n",
    "    'pressure' : 'photon_diagnostics/FEL01/Gas_Attenuator/Pressure',\n",
    "    'poletto' : 'cosp/HorSpectrum',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ! Data selection !\n",
    "\n",
    "This block contains the variables you might change every different Run. \n",
    "Changing \"ion_tof_range\" or \"eon_tof_range\" __does not__ make the program run faster; we are limited\n",
    "by the compression in FERMI's HDF5 files. If working memory is a problem, then decrease these\n",
    "ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BEAMTIME_DIR =  '/net/online4ldm/store/20234049/results/Beamtime/'  # expected directory at FERMI\n",
    "BEAMTIME_DIR =  f'{CURRENT_SCRIPT_DIR}/TestBeamtime/'\n",
    "BEAMTIME_DIR = find_subdir('TestBeamtime', resolve_path(CURRENT_SCRIPT_DIR, '..'))\n",
    "DATA_DIR = f'{BEAMTIME_DIR}/Beamtime/'  # change from fictitious to the real raw data directory!\n",
    "SAVE_DIR = f'{BEAMTIME_DIR}/results/evaluation/'#'/net/online4ldm/store/20234049/results/results' # ditto\n",
    "\n",
    "\n",
    "SAVE_FILES = False\n",
    "\n",
    "BACKGROUND = True  # Only set to False if you want to sum up everything\n",
    "NAMEADD = 'test' # your name here\n",
    "run_numbers = np.arange(1,3)\n",
    "\n",
    "\n",
    "# variables for data extraction ans rebinning\n",
    "ION_TOF_REBIN = 10\n",
    "ion_tof_range = (4000, 30000, 1) # select ion tof range for plotting\n",
    "new_ion_mq = np.linspace(0.1,200,num=1200)\n",
    "\n",
    "ion_tof_slices = [ion_tof_range]\n",
    "\n",
    "raw_ion_tof = np.arange(*ion_tof_slices[0])\n",
    "ion_tof = raw_ion_tof[::ION_TOF_REBIN]\n",
    "\n",
    "MAKE_CACHE = True\n",
    "LOAD_FROM_CACHE = False\n",
    "\n",
    "CALIBRATION_RUN_NUMBER = 1\n",
    "\n",
    "print(run_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RunCollection (main data structure), and print location of our save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block loads all the relevent HDF5 filepaths into their respective Run.\n",
    "RunCollection = {}  # We will put all the 'Runs' in thes dictionary\n",
    "for run_id in (list(run_numbers) + [CALIBRATION_RUN_NUMBER,]):\n",
    "    folderpath = os.path.join(DATA_DIR, f'Run_{run_id:03d}/rawdata')\n",
    "    filepaths = [folderpath+'/'+filename for filename in os.listdir(folderpath)[::]]\n",
    "    RunCollection[run_id] = Run(filepaths,\n",
    "                                alias_dict=alias_dict, search_symbols=search_symbols,\n",
    "                                keyword_functions=keyword_functions,\n",
    "                                )  # create a Run object with its respective filepaths\n",
    "\n",
    "# This creates a set out of the run_numbers selected above\n",
    "BasicRunSet = RunSets([])\n",
    "for run in run_numbers:\n",
    "    BasicRunSet.add([RunCollection[run]])\n",
    "print(f'Data set contains {len(BasicRunSet.run_instances)} run(s).')\n",
    "\n",
    "run_name = f'Runs {run_numbers[0]}-{run_numbers[-1]}'\n",
    "run_string = name_from_runs(run_numbers)\n",
    "prefix = os.path.join(SAVE_DIR, run_string)\n",
    "outdir = (prefix + '_' + NAMEADD).rstrip('_')\n",
    "print(f'Save directory: ...{outdir[30:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directory if non-existent (and if we are actually saving files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_FILES:\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Show Run-averaged background-subtracted ion TOF\n",
    "\n",
    "The output for Runset.averageRunData and Runset.average_run_data_weights has the\n",
    "axes shape (rule, condition, run, data):\n",
    "\"rule\" are the filtering rules\n",
    "\"condition\" is in the order (FEL:ON SLU:ON, FEL:OFF SLU:ON, FEL:ON SLU:OFF, FEL:OFF SLU:OFF)\n",
    "\"run\" are the individual Runs\n",
    "\"data\" is the average rundata/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runset_ion_tof_data = BasicRunSet.average_run_data('ion_tof', back_sep=BACKGROUND,\n",
    "                                    slice_range=ion_tof_slices,\n",
    "                                    make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
    "fore_ion_tof_rawdata, back_ion_tof_rawdata, *_ = simplify_data(runset_ion_tof_data, single_rule=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_integral_eKE = []\n",
    "# fel_energys = nm_to_ev(fel_wavelengths)\n",
    "\n",
    "subt_ion_tof_rawdata = -(fore_ion_tof_rawdata - back_ion_tof_rawdata)\n",
    "ion_tof_spec = rebinning(ion_tof, raw_ion_tof, subt_ion_tof_rawdata, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "for (runnumber, ion_tof_spec_i) in zip( run_numbers, ion_tof_spec):\n",
    "    ax.plot(ion_tof, ion_tof_spec_i, label=f\"Run_{runnumber:03d}\")\n",
    "ax.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
    "ax.set_xlabel('ion TOF')\n",
    "ax.set_ylabel('ion TOF signal; rebinned (arb.u.)')\n",
    "ax.set_title(f'{run_name}: run averages')\n",
    "ax.set_ylim(-1,1)\n",
    "\n",
    "if SAVE_FILES: fig.savefig(outdir+'/Average_of_complete_run.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ion TOF calibration constants obtained from \"tof_to_mq_calibration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ion_t0 = 6059.316278073492\n",
    "ion_propconst = 7.440783535983542e-07 \n",
    "ion_constants = ion_t0, ion_propconst\n",
    "\n",
    "print(f\"Using ion constants: (t0, C) = {ion_constants}\")\n",
    "tof_to_mq = lambda tof, spec, axis=None: tof_to_mq_conversion(tof, spec, *ion_constants, axis=axis)\n",
    "mq_to_tof = lambda mq, spec, axis=None: mq_to_tof_conversion(mq, spec, *ion_constants, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,4))\n",
    "for (runnumber, ion_tof_spec_i) in zip(run_numbers, ion_tof_spec):\n",
    "    ax1.plot(ion_tof, ion_tof_spec_i, label=f\"Run_{runnumber:03d}\")\n",
    "\n",
    "ax1.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
    "ax1.set_xlabel('ion TOF')\n",
    "ax1.set_ylabel('ion TOF signal; rebinned (arb.u.)')\n",
    "ax1.set_title(f'{run_name}: run averages')\n",
    "\n",
    "mq_raw_coor, mq_raw_spectrum = tof_to_mq(ion_tof, ion_tof_spec, axis=1)\n",
    "mq_coor = np.linspace(0.1, 70, num=1000)\n",
    "mq_spectra = rebinning(mq_coor, mq_raw_coor, mq_raw_spectrum, axis=1)\n",
    "for (runnumber, mq_spec_i) in zip(run_numbers, mq_spectra):\n",
    "    ax2.plot(mq_coor, mq_spec_i, label=f\"Run_{runnumber:03d}\")\n",
    "\n",
    "ax2.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
    "ax2.set_xlabel('m/q')\n",
    "ax2.set_ylabel('ion TOF signal; rebinned (arb.u.)')\n",
    "# ax2.set_yscale('log')\n",
    "ylim = ax2.set_ylim()\n",
    "# ax2.set_ylim(ylim[1]*1e-4, ylim[1])\n",
    "ax2.set_title(f'{run_name}: run averages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# I0M filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_i0m_rundata = BasicRunSet.give_rundata('i0m', make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
    "try:\n",
    "    i0m_runset_data, *_ = simplify_data(raw_i0m_rundata, single_rule=True)  # can use simplify_data, because no rules\n",
    "except:\n",
    "    fore_rundata_i0m, back_rundata_iom, *_ = raw_i0m_rundata\n",
    "    i0m_runset_data = fore_rundata_i0m\n",
    "    for i in range(len(i0m_runset_data)):  # collapse the rule dimension\n",
    "        i0m_runset_data[i] = i0m_runset_data[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the range of possible I0M intensities here; change I0M binning in the next block if needed!\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "for runnumber, i0m_run_data in zip(run_numbers, i0m_runset_data):\n",
    "    i0m_data = i0m_run_data[:,0]  # just collapsing an extraneous dimension\n",
    "    ax1.plot(i0m_data, marker='o', markersize=1, linestyle='', label=f'Run_{runnumber:03d}')\n",
    "    ax2.hist(i0m_data, bins=np.linspace(min(i0m_data),max(i0m_data),num=100),\n",
    "             label=f'Run_{runnumber:03d}')\n",
    "ax1.set_ylabel('I0M intensity (uJ)')\n",
    "ax1.set_xlabel('shot number')\n",
    "ax1.set_title(f'{run_name}: I0M over time')\n",
    "ax1.legend()\n",
    "#ax1.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
    "\n",
    "ax2.set_ylabel('binned counts')\n",
    "ax2.set_xlabel('I0M (uJ)')\n",
    "ax2.set_title(f'{run_name}: Histogram of I0M')\n",
    "ax2.legend()\n",
    "#ax2.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0, ncol = 2)\n",
    "plt.tight_layout()\n",
    "\n",
    "if SAVE_FILES:\n",
    "    plt.savefig(outdir+'/I0M_time_and_bins.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time # uncomment to show time\n",
    "runset_vmi = BasicRunSet.average_run_data('vmi',back_sep=BACKGROUND,\n",
    "                                    make_cache=MAKE_CACHE, use_cache=LOAD_FROM_CACHE)\n",
    "fore_vmi, back_vmi, *_ = simplify_data(runset_vmi, single_rule=True, single_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delays = BasicRunSet.average_run_data('delay',back_sep=False,\n",
    "                                    make_cache=False, use_cache=False)\n",
    "delays, *_ = simplify_data(delays, single_rule=True, single_run=False)\n",
    "delays = np.squeeze(delays)\n",
    "print(delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show VMI and resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpbasex.gData import loadG\n",
    "from cpbasex.cpbasex import cpbasex as cpbasex_inversion, cpbasex_energy as cpbasex_energy_inversion\n",
    "from cpbasex.image_mod import resizeFoldedHalf, foldHalf\n",
    "\n",
    "sub_vmi = fore_vmi - back_vmi\n",
    "sub_vmi = sub_vmi.transpose(1,2,0)\n",
    "print(np.shape(sub_vmi))\n",
    "plt.imshow(sub_vmi[:,:,0])\n",
    "plt.title(f'VMI of Run {run_numbers[0]:03d}')\n",
    "plt.show()\n",
    "\n",
    "rebinned_vmi = rebinning(np.linspace(0, 900, 512), np.arange(900), sub_vmi, axis=1)\n",
    "rebinned_vmi = rebinning(np.linspace(0, 900, 512), np.arange(900), rebinned_vmi, axis=0)\n",
    "\n",
    "plt.imshow(rebinned_vmi[:,:,0])\n",
    "plt.title(f'rebinned VMI of Run {run_numbers[0]:03d}')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "x0, y0 = 264, 260\n",
    "half_filter = [1,1]\n",
    "folded = foldHalf(rebinned_vmi, x0=x0, y0=y0, half_filter=half_filter)\n",
    "resized = resizeFoldedHalf(folded, 256)\n",
    "\n",
    "plt.imshow(resized[:,:,0])\n",
    "plt.title('half-folded')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Abel inversion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_IMAGES = True\n",
    "PROJECT_DIRECTORY = resolve_path(CURRENT_SCRIPT_DIR, '../..')\n",
    "gData = loadG(f'{PROJECT_DIRECTORY}/G_r256_k64_l4_half.h5', make_images=MAKE_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the pBASEX algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cpbasex_energy_inversion(resized, gData, make_images=True, alpha=1, shape='half')\n",
    "\n",
    "raw = rebinned_vmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_cal_constant = 1e-4\n",
    "energies = out['E'] * energy_cal_constant\n",
    "pes = out['IE'] / energy_cal_constant\n",
    "plt.pcolormesh(delays, energies, pes)\n",
    "plt.xlabel('delay (fs)')\n",
    "plt.ylabel('eKE (eV)')\n",
    "plt.title(f'PES for Runs {run_numbers[0]:03d}-{run_numbers[-1]:03d}')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
